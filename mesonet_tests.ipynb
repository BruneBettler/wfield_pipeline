{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6bb0d7f8afe368",
   "metadata": {},
   "source": [
    "# MesoNet \n",
    "\n",
    "MesoNet can be used either through a GUI or the command line interface (CLI). This notebook will make use of the CLI. \n",
    "\n",
    "While MesoNet can be used through 5 different \"approaches\", this notebook will focus on the following two:\n",
    "\n",
    "ATLAS -> BRAIN: \n",
    "- Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, this approach registers an atlas of brain regions to the fixed brain imaging data using affine transformations. This approach is useful if your data has common anatomical landmarks and is the most robust to variations in image quality and orientation within your data.\n",
    "\n",
    "BRAIN -> ATLAS:\n",
    "- Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, the brain imaging data is fixed onto an atlas of brain regions using affine transformations. This approach is useful if you would like to normalize your brain images to a common template based on anatomical landmarks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c05ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(DEEPLABCUT) c:\\Users\\bbettl\\PycharmProjects\\wfield_pipeline>conda.bat activate DEEPLABCUT \n"
     ]
    }
   ],
   "source": [
    "# make sure to activate your DEEPLABCUT environment before processing any data. \n",
    "!activate DEEPLABCUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb2185d9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set verbose to True if you want to get feedback from each cell\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "474620f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "\n",
    "import mesonet\n",
    "from data_loading_functions import *\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os \n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib as mpl \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ddeb80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "# Data Preparation: \n",
    "### dat or .npy --> .png\n",
    "\n",
    "MesoNet requires that images be in an 8-bit (value 0-255) .png files in order to be used. \n",
    "The pipeline however currently allows a series of possible options. \n",
    "\n",
    "All input data for a single session / processing run must be in a single directory containing one of the following: \n",
    "1. a single .dat file\n",
    "2. a series of .png brain images (may also contain a .dat file but NO .npy files)\n",
    "\n",
    "An output directory within `Data_outputs` will be created with the current date and time in order to keep track of all processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30c63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the path to the input and output directories as specified above\n",
    "input_dir = \"Data_inputs\"\n",
    "output_dir = \"Data_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "889ce9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to move .npy files from the input_dir directory into a np_files directory\n",
    "# helper function to remove all .png files from input_dir directory. Used for debugging and testing\n",
    "\n",
    "def move_np_files(source_dir, target_dir):\n",
    "    np_file_num = len(glob.glob((os.path.join(source_dir, '*.npy'))))\n",
    "\n",
    "    # if there are no npy files, return funtion\n",
    "    if np_file_num != 0:\n",
    "        # check if a np_files directory exists. If not, make one\n",
    "        if not os.path.exists(target_dir): os.makedirs(target_dir) \n",
    "        \n",
    "        # iterate through all .npy files and move them to the target_dir\n",
    "        [shutil.move(file, os.path.join(target_dir, os.path.basename(file))) for file in glob.glob(os.path.join(source_dir, '*.npy'))]\n",
    "        \n",
    "        return np_file_num\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def remove_png_files(source_dir):\n",
    "    files_to_remove = glob.glob(os.path.join(source_dir, '*.png'))\n",
    "    file_num = len(files_to_remove)\n",
    "\n",
    "    # Iterate through all .png files and remove them with a progress bar\n",
    "    for im in tqdm(files_to_remove, desc=\"Removing .png images\", unit=\"image\"):\n",
    "        os.remove(im)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Finished removing all {file_num} .png files from {source_dir}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb2dcd0f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy stack successfully loaded from .dat file. It has shape: (11220, 1, 640, 540).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving images: 100%|██████████| 500/500 [00:19<00:00, 26.25image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 .png files have been created in the Data_inputs direcotry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# our pipeline works with a stack of np arrays representing the wfield images.\n",
    "# prepare the data as it would appear after coming out of the preprocessing pipeline.\n",
    "# For this example, we will load only 500 of the original 10000+ brain images. \n",
    "\n",
    "# check if there are .png images already present in the Data_inputs folder.\n",
    "if len(glob.glob(f\"{input_dir}/*.png\")) != 0: # there are images present\n",
    "    if verbose: print(\"Make sure images are 8-bit (0-255 value) before proceeding.\")\n",
    "\n",
    "else: # There must be a .dat file\n",
    "    # make a numpy array from the .dat file\n",
    "    np_img_stack = load_dat_frames(filename=glob.glob(os.path.join(input_dir, '*.dat'))[0])\n",
    "    if verbose: print(f\"numpy stack successfully loaded from .dat file. It has shape: {np_img_stack.shape}.\")\n",
    "\n",
    "    # make sure the array is of correct dimension: we only want access to the blue frames (single channel)\n",
    "    if len(np_img_stack.shape) == 4:\n",
    "        if np_img_stack.shape[1] != 1:\n",
    "            np_img_stack = np_img_stack[:,0,...]\n",
    "        np_img_stack = np.squeeze(np_img_stack, axis=1)\n",
    "    \n",
    "    # TODO: remove the lightweight option when making full version of this code. \n",
    "    np_img_stack = np_img_stack[:500,...]\n",
    "\n",
    "    # make sure all array is of type uint8 with values 0-255\n",
    "    if np_img_stack.dtype == 'uint16':\n",
    "        # normalize the values to be between 0-1\n",
    "        normalized_stack = (np_img_stack - np.min(np_img_stack)) / (np.max(np_img_stack) - np.min(np_img_stack))\n",
    "        # scale to range 0-255\n",
    "        scaled_stack = normalized_stack * 255.0\n",
    "        # convert to uint8\n",
    "        np_img_stack = scaled_stack.astype(np.uint8)\n",
    "    \n",
    "    # Convert the NumPy stack into a series of .png images with a progress bar\n",
    "    for i, im in enumerate(tqdm(np_img_stack, desc=\"Saving images as .png\", unit=\"image\")):\n",
    "        im_file_name = os.path.join(input_dir, f\"frame_{i}.png\")\n",
    "        Image.fromarray(im).save(im_file_name)\n",
    "    \n",
    "    if verbose: print(f\"{i+1} .png files have been created in the {input_dir} direcotry.\")\n",
    "\n",
    "\n",
    "# make sure there are no .npy files in the Data_inputs directory as this will impact the MesoNet processing\n",
    "np_file_num = move_np_files(input_dir, \"np_files\")\n",
    "if verbose:\n",
    "    if np_file_num > 0: print(f\"{np_file_num} numpy files were moved from {input_dir} to the np_files directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90f57a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing .png images: 100%|██████████| 500/500 [00:00<00:00, 8432.46image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished removing all 500 .png files from Data_inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run this cell to clear all the .png images in the Data_inputs folder\n",
    "remove_png_files(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb7cfa",
   "metadata": {},
   "source": [
    "---\n",
    "# MesoNet Models\n",
    "\n",
    "- U-Net (.hdf5)\n",
    "- VoxelMorph (.h5) \n",
    "\n",
    "All models need to be in a folder called `models` within the *mesonet* directory of the MesoNet git repo.\n",
    "\n",
    "### Configuration files:\n",
    "\n",
    "The configuration file is used to customize the MesoNet analysis. It is created in the `output_dir` location \n",
    "The full list of configuration parameters can be found [here](https://github.com/bf777/MesoNet/wiki/Config-File-Guide).\n",
    "\n",
    "\n",
    "##### Model Training params of interest: \n",
    "\n",
    "- <ins>**epochs**</ins> default 60: The number of epochs for which the model will be trained. You may wish to reduce this number if you're updating an existing model.\n",
    "\n",
    "- <ins>**log_folder**</ins> folder to which logging data should be output (and where this config file will be saved)\n",
    "\n",
    "- <ins>**steps_per_epoch**</ins> default 300: The number of steps per training epoch. Influences the pace at which the model is trained.\n",
    "\n",
    "\n",
    "\n",
    "#### Model Testing params of interest: \n",
    "\n",
    "- <ins>**model**</ins> location (within the MesoNet repository) of a U-Net model to be used for finding the boundaries of the brain region (as the default model does), or (if you have a specially trained model for this purpose) segmenting the entire brain into regions without the need for atlas alignment. Only choose another model if you have another model that you would like to use for segmenting the brain.\n",
    "\n",
    "- <ins>**threshold**</ins> adjusts the sensitivity of the algorithm used to define individual brain regions from the brain atlas. Changing this number may significantly change the quality of the brain region predictions\n",
    "    - increasing this number causes each brain region contour to be smaller (less like the brain atlas)\n",
    "    - decreasing this number causes each brain region contour to be larger (more like the brain atlas).\n",
    "\n",
    "- <ins>**olfactory_check**</ins> when True, draws olfactory bulb contours on brain image\n",
    "\n",
    "- <ins>**align_once**</ins> if True, carries out all alignments based on the alignment of the first atlas and brain. This can save time if you have many frames of the same brain with a fixed camera position.\n",
    "\n",
    "- <ins>**atlas_label_list**</ins> list of aligned atlases in which each brain region is filled with a unique numeric label. Allows for consistent identification of brain regions across images. If original_label is True, this is an empty list.\n",
    "\n",
    "- <ins>**landmark_arr**</ins> The default number and order of landmarks to be used for the full alignment of a standard brain atlas to a brain image. Change what is contained in this list to change the landmarks used. When the default DeepLabCut model with nine landmarks, the landmarks are\n",
    "    - 0: Anterolateral tip of the left parietal bone.\n",
    "    - 1: Left frontal pole.\n",
    "    - 2: Posterior tip of the left retrosplenial region.\n",
    "    - 3: Cross point between the median line and the line which connects the left and right frontal pole.\n",
    "    - 4: Bregma (centre point of cortex)\n",
    "    - 5: Anterior tip of the interparietal bone.\n",
    "    - 6: Anterolateral tip of the right parietal bone.\n",
    "    - 7: Right frontal pole.\n",
    "    - 8: Posterior tip of the right retrosplenial region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984590b2c550737",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Training:\n",
    "\n",
    "We will be using the same `input_dir` and `output_dir` variables as previously loaded. Make sure these are correctly intiialized before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd45555738db4",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Testing:\n",
    "\n",
    "We will be using the same `input_dir` and `output_dir` variables as previously loaded. Make sure these are correctly intiialized before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa64ea9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe086e1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x107e4e910>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brune/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/mesonet/utils.py:246\u001b[0m, in \u001b[0;36mfind_git_repo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     git_repo_base \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMESONET_GIT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmesonet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMesoNet git repo found at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, skipping directory check...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    249\u001b[0m             git_repo_base\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    251\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mIf any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03mwill be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m sep \u001b[38;5;241m=\u001b[39m _get_sep(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/output/folder\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# prepare a configure file that will be used to ___\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m config_file \u001b[38;5;241m=\u001b[39m \u001b[43mmesonet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_file has been created with input_file and output_file paths\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/mesonet/utils.py:138\u001b[0m, in \u001b[0;36mconfig_project\u001b[0;34m(input_dir, output_dir, mode, model_name, config, atlas, sensory_match, sensory_path, mask_generate, mat_save, use_unet, use_dlc, atlas_to_brain_align, olfactory_check, plot_landmarks, align_once, original_label, use_voxelmorph, exist_transform, voxelmorph_model, template_path, flow_path, coords_input_file, atlas_label_list, threshold, model, region_labels, steps_per_epoch, epochs, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip, fill_mode)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mGenerates a config file (mesonet_train_config.yaml or mesonet_test_config.yaml, depending on whether you are\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mapplying an existing model or training a new one).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# git_repo_base = 'C:/Users/mind reader/Desktop/mesonet/mesonet'\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m git_repo_base \u001b[38;5;241m=\u001b[39m \u001b[43mfind_git_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(git_repo_base)\n\u001b[1;32m    140\u001b[0m config \u001b[38;5;241m=\u001b[39m join(git_repo_base, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/mesonet/utils.py:283\u001b[0m, in \u001b[0;36mfind_git_repo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m in_colab:\n\u001b[1;32m    282\u001b[0m     root_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(root_folder):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m git_repo_marker \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m    285\u001b[0m         git_repo_base \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/os.py:418\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 418\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/os.py:418\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 418\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n",
      "    \u001b[0;31m[... skipping similar frames: _walk at line 418 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/os.py:418\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 418\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/os.py:367\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m         entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscandir_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare a configuration file that will be used to ___\n",
    "config_file = mesonet.config_project(input_file, output_file, 'test')\n",
    "\n",
    "if verbose: \"config_file has been created with input_file and output_file paths\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1116702e25396",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef1602",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mesonet.predict_regions(config_file)\n",
    "mesonet.predict_dlc(config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
